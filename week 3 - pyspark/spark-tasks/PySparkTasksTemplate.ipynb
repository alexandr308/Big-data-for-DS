{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   @@@@@@@     @      @    @  @   #\n",
    "#   @  @  @    @ @      @  @       #\n",
    "#      @  @   @   @      @@    @   #\n",
    "#      @     @@@@@@@    @  @   @   #\n",
    "#      @    @       @  @    @  @   #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, в этой практике мы с вами применим наши знания по PySpark и постараемся изучить что-то новое в процессе выполнения.\n",
    "<br>В занятии используется датасет собранный на основе данных <a href=\"https://www.kaggle.com/chicago/chicago-taxi-rides-2016\">Chicago Taxi Rides 2016</a>\n",
    "<br>Полная <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\">документация PySpark</a>.\n",
    "<br>Схема данны:\n",
    "<br>|-- taxi_id = идентификатор таксиста\n",
    "<br>|-- trip_start_timestamp = время начала поездки\n",
    "<br>|-- trip_end_timestamp = время окончания поездки\n",
    "<br>|-- trip_seconds = время длительности поездки в секундах\n",
    "<br>|-- trip_miles = мили проиденные во время поездки\n",
    "<br>|-- fare = транспортные расходы\n",
    "<br>|-- tips = назначенные чаевые\n",
    "<br>|-- trip_total = общая стоимость поездки (Итоговая с учетом чаевых и расходов)\n",
    "<br>|-- payment_type = тип оплаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, max, min, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('PySparkTasks').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT+3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://735c53c74915:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTasks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f68ffe21850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/spark-tasks/taxi_data.parquet\">taxi_data.parquet</a> и загрузите используя <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\">SparkAPI</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('taxi_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№1 Посчитайте количество загруженных строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # Число строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+------------+----------+-----+----+----------+------------+\n",
      "|taxi_id|trip_start_timestamp| trip_end_timestamp|trip_seconds|trip_miles| fare|tips|trip_total|payment_type|\n",
      "+-------+--------------------+-------------------+------------+----------+-----+----+----------+------------+\n",
      "|   5240| 2016-12-15 23:45:00|2016-12-16 00:00:00|         900|       2.5|10.75|2.45|      14.7| Credit Card|\n",
      "|   1215| 2016-12-12 07:15:00|2016-12-12 07:15:00|         240|       0.4|  5.0| 3.0|       9.5| Credit Card|\n",
      "|   3673| 2016-12-16 16:30:00|2016-12-16 17:00:00|        2400|      10.7| 31.0| 0.0|      31.0|        Cash|\n",
      "|   5400| 2016-12-16 08:45:00|2016-12-16 09:00:00|         300|       0.0| 5.25| 2.0|      7.25| Credit Card|\n",
      "|   1257| 2016-12-03 18:45:00|2016-12-03 18:45:00|         360|       0.3|  5.0| 0.0|       5.0|        Cash|\n",
      "+-------+--------------------+-------------------+------------+----------+-----+----+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим схему данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- taxi_id: integer (nullable = true)\n",
      " |-- trip_start_timestamp: timestamp (nullable = true)\n",
      " |-- trip_end_timestamp: timestamp (nullable = true)\n",
      " |-- trip_seconds: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- trip_total: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№2 Чему равна корреляция и ковариация между длиной маршрута и ценой за поездку? Ответ округлите до 5 знаков после запятой.\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.corr.html?highlight=corr#pyspark-sql-dataframe-corr\">corr</a> & <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.cov.html?highlight=cov#pyspark-sql-dataframe-cov\">cov</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44816"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.corr('trip_miles', 'trip_total'), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.96914"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.cov('trip_miles', 'trip_total'), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№3 Найдите количество, среднее, cреднеквадратическое отклонение, минимум и максимум для длины маршрута и цены за поездку? Ответ округлите до 1 знака после запятой. Подробнее <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.describe.html?highlight=describe#pyspark-sql-dataframe-describe\">describe</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|        trip_miles|        trip_total|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           2540677|           2540672|\n",
      "|   mean|3.0005873828090266|15.913560215564042|\n",
      "| stddev|  5.25716922943536|30.546699217618237|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|             900.0|           9276.69|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['trip_miles', 'trip_total']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "округленные количества значений колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540677"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(count(col('trip_miles'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540672"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(count(col('trip_total'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "округленные средние значения колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(avg(col('trip_miles'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(avg(col('trip_total'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "округленные стандартные отклонения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(stddev(col('trip_miles'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(stddev(col('trip_total'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "округленные минимальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(min(col('trip_miles'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(min(col('trip_total'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "округленные максимальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(max(col('trip_miles'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9276.7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.select(max(col('trip_total'))).collect()[0][0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№4 Найдите самый НЕпопулярный вид оплаты.\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html?highlight=groupby#pyspark-sql-dataframe-groupby\">groupBy</a> <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.orderBy.html?highlight=orderby#pyspark-sql-dataframe-orderby\">orderBy</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Way2ride'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('payment_type').count().orderBy('count', ascending=True).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№5 Найдите идентификатор таксиста выполнившего наибольшее число заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('taxi_id').count().orderBy('count', ascending=False).collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№6 Чему равна средняя цена среди поездок, оплаченных наличными? Ответ округлите до 5 знака.\n",
    "<br> Подробней <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.where.html?highlight=where#pyspark-sql-dataframe-where\">where</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cash = df.where(col('payment_type') == 'Cash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.03526"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_cash.select(avg(col('trip_total'))).collect()[0][0], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№7 Сколько таксистов проехало больше 1000 миль за все время выполнения заказов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2860"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('taxi_id').sum('trip_miles').where('sum(trip_miles) > 1000').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№8 Сколько миль проехал пассажир в самой долгой поездке? (Ответ округлите до целого)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.orderBy('trip_seconds', ascending=False).where(col('trip_seconds')\\\n",
    "                                                        .isNull() == False).select('trip_miles').collect()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№9 Каков средний заработок всех таксистов? Ответ округлите до 5-ого знака.\n",
    "<br>Отсеките неизвестные машины (не определенный taxi_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8218.85627"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.where(col('taxi_id').isNotNull()).groupBy('taxi_id').sum('trip_total')\\\n",
    "                          .select(avg(col('sum(trip_total)'))).collect()[0][0], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№10 Сколько поездок начиналось в самый загруженный час?\n",
    "<br>Используйте функцию <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.functions.hour.html?highlight=hour#pyspark-sql-functions-hour\">hour</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|hour| count|\n",
      "+----+------+\n",
      "|  18|181127|\n",
      "+----+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(hour('trip_start_timestamp').alias('hour')).groupBy('hour').count().orderBy('count', ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№11 Сколько поездок началось во второй четверти суток?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hours = df.withColumn('hour', hour('trip_start_timestamp')).groupBy('hour').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|    538737|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hours.where((col('hour') > 5) & (col('hour') < 12)).agg({'count':'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№12 Найдите топ три даты, в которые было суммарно больше всего чаевых? (Чаевые выдаются после совершения поездки)\n",
    "<br> Ожидаемый формат дат YYYY-MM-DD\n",
    "<br>Вам может понадобится конвертация типов <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.Column.cast.html?highlight=cast#pyspark-sql-column-cast\">cast</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      date|         sum(tips)|\n",
      "+----------+------------------+\n",
      "|2016-11-03|110102.37000000013|\n",
      "|2016-11-09|106187.87999999986|\n",
      "|2016-11-16| 99993.77000000038|\n",
      "+----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['trip_end_timestamp'].cast('date').alias('date'), df['tips']).groupBy('date')\\\n",
    "                                    .agg({\"tips\":'sum'}).orderBy('sum(tips)', ascending=False).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№13 Сколько было заказов в дату с наибольшим спросом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      date|count|\n",
      "+----------+-----+\n",
      "|2016-11-03|61259|\n",
      "+----------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['trip_start_timestamp'].cast('date').alias('date')).groupBy('date')\\\n",
    "                                    .count().orderBy('count', ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузите данные о марках машин из датасета <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/spark-tasks/taxi_cars_data.parquet\">taxi_cars_data.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = spark.read.parquet('taxi_cars_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|taxi_id|          car_model|\n",
      "+-------+-------------------+\n",
      "|   1159|       Toyota Prius|\n",
      "|   7273|Ford Crown Victoria|\n",
      "|   2904|        Honda Civic|\n",
      "|   3210|        Ford Fusion|\n",
      "|   2088|       Toyota Camry|\n",
      "|   4821|Ford Crown Victoria|\n",
      "|   2069|    Hyundai Elantra|\n",
      "|   6240|       Toyota Camry|\n",
      "|    296|     Hyundai Sonata|\n",
      "|   2136|Ford Crown Victoria|\n",
      "|   1436|     Toyota Corolla|\n",
      "|   1090|     Toyota Corolla|\n",
      "|   7711|        Lincoln MKZ|\n",
      "|   1572|Ford Crown Victoria|\n",
      "|   3959|     Chevrolet Aveo|\n",
      "|   5645|  Chevrolet Lacetti|\n",
      "|   5149|            Audi A7|\n",
      "|   6366|     Hyundai Sonata|\n",
      "|    451|     Hyundai Accent|\n",
      "|   1669|           Kia Ceed|\n",
      "+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№14 Какая марка машины самая распрастранненая среди таксистов?\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.functions.split.html?highlight=split#pyspark-sql-functions-split\">split</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|mark|count|\n",
      "+----+-----+\n",
      "|Ford| 1484|\n",
      "+----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.withColumn('mark', split(col('car_model'), ' ')[0]).groupBy('mark').count().orderBy('count', ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№15 Сколько раз и какая модель машин чаще всего встречается в поездках?\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.functions.split.html?highlight=split#pyspark-sql-functions-split\">join</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|          car_model| count|\n",
      "+-------------------+------+\n",
      "|Ford Crown Victoria|388682|\n",
      "+-------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df_car, on='taxi_id').groupBy('car_model').count().orderBy('count', ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почувствуй силу сжатия! сохрани DataFrame в csv и сравни размеры файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.coalesce(1).write.csv('taxi_data_csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузите данные из csv и проверьте типы методом printSchema()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read.csv('taxi_data_csv')\n",
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- taxi_id: integer (nullable = true)\n",
      " |-- trip_start_timestamp: timestamp (nullable = true)\n",
      " |-- trip_end_timestamp: timestamp (nullable = true)\n",
      " |-- trip_seconds: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- trip_total: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте посетить SparkUI и изучить историю ваших задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://735c53c74915:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTasks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f68ffe21850>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
